{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_다중분류.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 다중분류 iris 데이터\n",
        "- best model\n",
        "- 조기종료"
      ],
      "metadata": {
        "id": "EiYyPc16Lc_0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gyzV0QUZLYvo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "uESL8ssjLj2E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "iris_std = StandardScaler().fit_transform(iris.data)\n",
        "y_oh = to_categorical(iris.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_std , y_oh, stratify = y_oh, test_size = 0.2, random_state = seed\n",
        ")"
      ],
      "metadata": {
        "id": "0fuhzTRIMPiK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pFfSyZb3NYz6",
        "outputId": "54ab844f-ee1a-4528-a8d8-945eb2abc942"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의 및 설정"
      ],
      "metadata": {
        "id": "Pdks4bLjM5nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "uYvxkPbkMvGT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(12, input_dim = 4, activation='relu'),\n",
        "    Dense(7, activation='relu'),\n",
        "    Dense(3, activation='softmax'),\n",
        "])\n",
        "print(model.summary())\n",
        "model.compile('adam', 'categorical_crossentropy', ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sKa8DRGaNTQi",
        "outputId": "c6745ce3-e4d8-4cbb-f51c-fba96e1f6ecd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                60        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 175\n",
            "Trainable params: 175\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint('iris_best.h5', monitor='val_loss', \n",
        "                     verbose = 1, save_best_only = True)\n",
        "es = EarlyStopping(patience=30)"
      ],
      "metadata": {
        "id": "gDoqtAoyN76q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, validation_split = 0.2,\n",
        "                 epochs = 1000, batch_size = 100, verbose = 0,\n",
        "                 callbacks = [mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uAl3lEuyO0lf",
        "outputId": "4d93c265-3a14-4b40-b7e4-a248a9cf785e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.09823, saving model to iris_best.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.09823 to 0.09816, saving model to iris_best.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.09816 to 0.09814, saving model to iris_best.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.09814 to 0.09812, saving model to iris_best.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.09812 to 0.09812, saving model to iris_best.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.09812 to 0.09811, saving model to iris_best.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.09811 to 0.09809, saving model to iris_best.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.09809 to 0.09807, saving model to iris_best.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.09807 to 0.09804, saving model to iris_best.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.09804 to 0.09801, saving model to iris_best.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.09801 to 0.09799, saving model to iris_best.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 0.09799 to 0.09798, saving model to iris_best.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.09798 to 0.09796, saving model to iris_best.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.09796 to 0.09793, saving model to iris_best.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.09793 to 0.09792, saving model to iris_best.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.09792 to 0.09791, saving model to iris_best.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.09791 to 0.09790, saving model to iris_best.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.09790 to 0.09788, saving model to iris_best.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.09788 to 0.09786, saving model to iris_best.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.09786 to 0.09784, saving model to iris_best.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.09784 to 0.09782, saving model to iris_best.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.09782 to 0.09781, saving model to iris_best.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.09781 to 0.09779, saving model to iris_best.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.09779 to 0.09778, saving model to iris_best.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.09778 to 0.09775, saving model to iris_best.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.09775 to 0.09774, saving model to iris_best.h5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.09774 to 0.09773, saving model to iris_best.h5\n",
            "\n",
            "Epoch 28: val_loss improved from 0.09773 to 0.09771, saving model to iris_best.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.09771 to 0.09770, saving model to iris_best.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.09770 to 0.09767, saving model to iris_best.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.09767 to 0.09766, saving model to iris_best.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.09766 to 0.09765, saving model to iris_best.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.09765 to 0.09763, saving model to iris_best.h5\n",
            "\n",
            "Epoch 34: val_loss improved from 0.09763 to 0.09761, saving model to iris_best.h5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.09761 to 0.09758, saving model to iris_best.h5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.09758 to 0.09756, saving model to iris_best.h5\n",
            "\n",
            "Epoch 37: val_loss improved from 0.09756 to 0.09755, saving model to iris_best.h5\n",
            "\n",
            "Epoch 38: val_loss improved from 0.09755 to 0.09753, saving model to iris_best.h5\n",
            "\n",
            "Epoch 39: val_loss improved from 0.09753 to 0.09751, saving model to iris_best.h5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.09751 to 0.09749, saving model to iris_best.h5\n",
            "\n",
            "Epoch 41: val_loss improved from 0.09749 to 0.09747, saving model to iris_best.h5\n",
            "\n",
            "Epoch 42: val_loss improved from 0.09747 to 0.09746, saving model to iris_best.h5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.09746 to 0.09744, saving model to iris_best.h5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.09744 to 0.09742, saving model to iris_best.h5\n",
            "\n",
            "Epoch 45: val_loss improved from 0.09742 to 0.09740, saving model to iris_best.h5\n",
            "\n",
            "Epoch 46: val_loss improved from 0.09740 to 0.09737, saving model to iris_best.h5\n",
            "\n",
            "Epoch 47: val_loss improved from 0.09737 to 0.09735, saving model to iris_best.h5\n",
            "\n",
            "Epoch 48: val_loss improved from 0.09735 to 0.09734, saving model to iris_best.h5\n",
            "\n",
            "Epoch 49: val_loss improved from 0.09734 to 0.09733, saving model to iris_best.h5\n",
            "\n",
            "Epoch 50: val_loss improved from 0.09733 to 0.09732, saving model to iris_best.h5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.09732 to 0.09731, saving model to iris_best.h5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.09731 to 0.09729, saving model to iris_best.h5\n",
            "\n",
            "Epoch 53: val_loss improved from 0.09729 to 0.09727, saving model to iris_best.h5\n",
            "\n",
            "Epoch 54: val_loss improved from 0.09727 to 0.09724, saving model to iris_best.h5\n",
            "\n",
            "Epoch 55: val_loss improved from 0.09724 to 0.09721, saving model to iris_best.h5\n",
            "\n",
            "Epoch 56: val_loss improved from 0.09721 to 0.09719, saving model to iris_best.h5\n",
            "\n",
            "Epoch 57: val_loss improved from 0.09719 to 0.09718, saving model to iris_best.h5\n",
            "\n",
            "Epoch 58: val_loss improved from 0.09718 to 0.09718, saving model to iris_best.h5\n",
            "\n",
            "Epoch 59: val_loss improved from 0.09718 to 0.09717, saving model to iris_best.h5\n",
            "\n",
            "Epoch 60: val_loss improved from 0.09717 to 0.09716, saving model to iris_best.h5\n",
            "\n",
            "Epoch 61: val_loss improved from 0.09716 to 0.09714, saving model to iris_best.h5\n",
            "\n",
            "Epoch 62: val_loss improved from 0.09714 to 0.09712, saving model to iris_best.h5\n",
            "\n",
            "Epoch 63: val_loss improved from 0.09712 to 0.09710, saving model to iris_best.h5\n",
            "\n",
            "Epoch 64: val_loss improved from 0.09710 to 0.09708, saving model to iris_best.h5\n",
            "\n",
            "Epoch 65: val_loss improved from 0.09708 to 0.09708, saving model to iris_best.h5\n",
            "\n",
            "Epoch 66: val_loss improved from 0.09708 to 0.09707, saving model to iris_best.h5\n",
            "\n",
            "Epoch 67: val_loss improved from 0.09707 to 0.09705, saving model to iris_best.h5\n",
            "\n",
            "Epoch 68: val_loss improved from 0.09705 to 0.09703, saving model to iris_best.h5\n",
            "\n",
            "Epoch 69: val_loss improved from 0.09703 to 0.09701, saving model to iris_best.h5\n",
            "\n",
            "Epoch 70: val_loss improved from 0.09701 to 0.09700, saving model to iris_best.h5\n",
            "\n",
            "Epoch 71: val_loss improved from 0.09700 to 0.09700, saving model to iris_best.h5\n",
            "\n",
            "Epoch 72: val_loss improved from 0.09700 to 0.09700, saving model to iris_best.h5\n",
            "\n",
            "Epoch 73: val_loss improved from 0.09700 to 0.09699, saving model to iris_best.h5\n",
            "\n",
            "Epoch 74: val_loss improved from 0.09699 to 0.09697, saving model to iris_best.h5\n",
            "\n",
            "Epoch 75: val_loss improved from 0.09697 to 0.09695, saving model to iris_best.h5\n",
            "\n",
            "Epoch 76: val_loss improved from 0.09695 to 0.09694, saving model to iris_best.h5\n",
            "\n",
            "Epoch 77: val_loss improved from 0.09694 to 0.09694, saving model to iris_best.h5\n",
            "\n",
            "Epoch 78: val_loss improved from 0.09694 to 0.09694, saving model to iris_best.h5\n",
            "\n",
            "Epoch 79: val_loss improved from 0.09694 to 0.09693, saving model to iris_best.h5\n",
            "\n",
            "Epoch 80: val_loss improved from 0.09693 to 0.09691, saving model to iris_best.h5\n",
            "\n",
            "Epoch 81: val_loss improved from 0.09691 to 0.09690, saving model to iris_best.h5\n",
            "\n",
            "Epoch 82: val_loss improved from 0.09690 to 0.09689, saving model to iris_best.h5\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.09689\n",
            "\n",
            "Epoch 84: val_loss improved from 0.09689 to 0.09689, saving model to iris_best.h5\n",
            "\n",
            "Epoch 85: val_loss improved from 0.09689 to 0.09689, saving model to iris_best.h5\n",
            "\n",
            "Epoch 86: val_loss improved from 0.09689 to 0.09688, saving model to iris_best.h5\n",
            "\n",
            "Epoch 87: val_loss improved from 0.09688 to 0.09686, saving model to iris_best.h5\n",
            "\n",
            "Epoch 88: val_loss improved from 0.09686 to 0.09685, saving model to iris_best.h5\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.09685\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.09685\n",
            "\n",
            "Epoch 91: val_loss improved from 0.09685 to 0.09685, saving model to iris_best.h5\n",
            "\n",
            "Epoch 92: val_loss improved from 0.09685 to 0.09684, saving model to iris_best.h5\n",
            "\n",
            "Epoch 93: val_loss improved from 0.09684 to 0.09683, saving model to iris_best.h5\n",
            "\n",
            "Epoch 94: val_loss improved from 0.09683 to 0.09681, saving model to iris_best.h5\n",
            "\n",
            "Epoch 95: val_loss improved from 0.09681 to 0.09681, saving model to iris_best.h5\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.09681\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.09681\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.09681\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.09681\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.09681\n",
            "\n",
            "Epoch 101: val_loss improved from 0.09681 to 0.09681, saving model to iris_best.h5\n",
            "\n",
            "Epoch 102: val_loss improved from 0.09681 to 0.09680, saving model to iris_best.h5\n",
            "\n",
            "Epoch 103: val_loss improved from 0.09680 to 0.09678, saving model to iris_best.h5\n",
            "\n",
            "Epoch 104: val_loss improved from 0.09678 to 0.09677, saving model to iris_best.h5\n",
            "\n",
            "Epoch 105: val_loss improved from 0.09677 to 0.09676, saving model to iris_best.h5\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.09676\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.09676\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.09676\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.09676\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.09676\n",
            "\n",
            "Epoch 111: val_loss improved from 0.09676 to 0.09676, saving model to iris_best.h5\n",
            "\n",
            "Epoch 112: val_loss improved from 0.09676 to 0.09675, saving model to iris_best.h5\n",
            "\n",
            "Epoch 113: val_loss improved from 0.09675 to 0.09674, saving model to iris_best.h5\n",
            "\n",
            "Epoch 114: val_loss improved from 0.09674 to 0.09674, saving model to iris_best.h5\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 118: val_loss improved from 0.09674 to 0.09673, saving model to iris_best.h5\n",
            "\n",
            "Epoch 119: val_loss improved from 0.09673 to 0.09672, saving model to iris_best.h5\n",
            "\n",
            "Epoch 120: val_loss improved from 0.09672 to 0.09672, saving model to iris_best.h5\n",
            "\n",
            "Epoch 121: val_loss improved from 0.09672 to 0.09671, saving model to iris_best.h5\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.09671\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.09671\n",
            "\n",
            "Epoch 124: val_loss improved from 0.09671 to 0.09671, saving model to iris_best.h5\n",
            "\n",
            "Epoch 125: val_loss improved from 0.09671 to 0.09670, saving model to iris_best.h5\n",
            "\n",
            "Epoch 126: val_loss improved from 0.09670 to 0.09669, saving model to iris_best.h5\n",
            "\n",
            "Epoch 127: val_loss improved from 0.09669 to 0.09669, saving model to iris_best.h5\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.09669\n",
            "\n",
            "Epoch 134: val_loss improved from 0.09669 to 0.09668, saving model to iris_best.h5\n",
            "\n",
            "Epoch 135: val_loss improved from 0.09668 to 0.09667, saving model to iris_best.h5\n",
            "\n",
            "Epoch 136: val_loss improved from 0.09667 to 0.09665, saving model to iris_best.h5\n",
            "\n",
            "Epoch 137: val_loss improved from 0.09665 to 0.09664, saving model to iris_best.h5\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.09664\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.09664\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.09664\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.09664\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.09664\n",
            "\n",
            "Epoch 143: val_loss improved from 0.09664 to 0.09664, saving model to iris_best.h5\n",
            "\n",
            "Epoch 144: val_loss improved from 0.09664 to 0.09663, saving model to iris_best.h5\n",
            "\n",
            "Epoch 145: val_loss improved from 0.09663 to 0.09662, saving model to iris_best.h5\n",
            "\n",
            "Epoch 146: val_loss improved from 0.09662 to 0.09661, saving model to iris_best.h5\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.09661\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.09661\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.09661\n",
            "\n",
            "Epoch 150: val_loss improved from 0.09661 to 0.09661, saving model to iris_best.h5\n",
            "\n",
            "Epoch 151: val_loss improved from 0.09661 to 0.09659, saving model to iris_best.h5\n",
            "\n",
            "Epoch 152: val_loss improved from 0.09659 to 0.09659, saving model to iris_best.h5\n",
            "\n",
            "Epoch 153: val_loss did not improve from 0.09659\n",
            "\n",
            "Epoch 154: val_loss did not improve from 0.09659\n",
            "\n",
            "Epoch 155: val_loss did not improve from 0.09659\n",
            "\n",
            "Epoch 156: val_loss did not improve from 0.09659\n",
            "\n",
            "Epoch 157: val_loss improved from 0.09659 to 0.09658, saving model to iris_best.h5\n",
            "\n",
            "Epoch 158: val_loss improved from 0.09658 to 0.09657, saving model to iris_best.h5\n",
            "\n",
            "Epoch 159: val_loss improved from 0.09657 to 0.09657, saving model to iris_best.h5\n",
            "\n",
            "Epoch 160: val_loss did not improve from 0.09657\n",
            "\n",
            "Epoch 161: val_loss did not improve from 0.09657\n",
            "\n",
            "Epoch 162: val_loss did not improve from 0.09657\n",
            "\n",
            "Epoch 163: val_loss improved from 0.09657 to 0.09656, saving model to iris_best.h5\n",
            "\n",
            "Epoch 164: val_loss improved from 0.09656 to 0.09655, saving model to iris_best.h5\n",
            "\n",
            "Epoch 165: val_loss improved from 0.09655 to 0.09655, saving model to iris_best.h5\n",
            "\n",
            "Epoch 166: val_loss did not improve from 0.09655\n",
            "\n",
            "Epoch 167: val_loss did not improve from 0.09655\n",
            "\n",
            "Epoch 168: val_loss did not improve from 0.09655\n",
            "\n",
            "Epoch 169: val_loss did not improve from 0.09655\n",
            "\n",
            "Epoch 170: val_loss improved from 0.09655 to 0.09654, saving model to iris_best.h5\n",
            "\n",
            "Epoch 171: val_loss did not improve from 0.09654\n",
            "\n",
            "Epoch 172: val_loss improved from 0.09654 to 0.09654, saving model to iris_best.h5\n",
            "\n",
            "Epoch 173: val_loss improved from 0.09654 to 0.09653, saving model to iris_best.h5\n",
            "\n",
            "Epoch 174: val_loss did not improve from 0.09653\n",
            "\n",
            "Epoch 175: val_loss did not improve from 0.09653\n",
            "\n",
            "Epoch 176: val_loss improved from 0.09653 to 0.09653, saving model to iris_best.h5\n",
            "\n",
            "Epoch 177: val_loss did not improve from 0.09653\n",
            "\n",
            "Epoch 178: val_loss did not improve from 0.09653\n",
            "\n",
            "Epoch 179: val_loss improved from 0.09653 to 0.09653, saving model to iris_best.h5\n",
            "\n",
            "Epoch 180: val_loss improved from 0.09653 to 0.09652, saving model to iris_best.h5\n",
            "\n",
            "Epoch 181: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 182: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 183: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 184: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 185: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 186: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 187: val_loss did not improve from 0.09652\n",
            "\n",
            "Epoch 188: val_loss improved from 0.09652 to 0.09651, saving model to iris_best.h5\n",
            "\n",
            "Epoch 189: val_loss improved from 0.09651 to 0.09651, saving model to iris_best.h5\n",
            "\n",
            "Epoch 190: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 191: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 192: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 193: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 194: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 195: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 196: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 197: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 198: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 199: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 200: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 201: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 202: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 203: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 204: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 205: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 206: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 207: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 208: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 209: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 210: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 211: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 212: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 213: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 214: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 215: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 216: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 217: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 218: val_loss did not improve from 0.09651\n",
            "\n",
            "Epoch 219: val_loss did not improve from 0.09651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('iris_best.h5')\n",
        "best_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "E9Yv70jNPMka",
        "outputId": "da320750-59dd-46ad-efb6-0199f7bc016f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1605 - accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1605035960674286, 0.9333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_acc = hist.history['accuracy']\n",
        "y_vloss = hist.history['val_loss']\n",
        "xs = np.arange(1, len(y_acc) + 1)\n",
        "\n",
        "plt.figure(figsize = (10, 7))\n",
        "plt.plot(xs, y_acc, label = 'accuracy')\n",
        "plt.plot(xs, y_vloss, label = 'validation_loss')\n",
        "plt.grid(linestyle = ':')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "T6WThdKKPlhR",
        "outputId": "636fa202-b056-4321-95c4-f5ed8837d087"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}